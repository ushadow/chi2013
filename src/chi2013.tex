\documentclass{sigchi}

% Remove or comment out these two lines for final version
\toappearbox{\Large Submitted to CHI'13. \\Do not cite, do not circulate.}
\pagenumbering{arabic}% Arabic page numbers for submission. 

% Use \toappear{...} to override the default ACM copyright statement (e.g. for preprints).

% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphicx} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage{url}      % llt: nicely formatted URLs
\usepackage{tabularx}
\usepackage{subfigure}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}


% End of preamble. Here it comes the document.
\begin{document}

\title{Making Touchscreen Keyboards Adaptive to Letters Keys, Hand Postures,  
and Individual Users - An Hierarchical Spatial Back-off Model Approach}

% Note that submissions are blind, so author information should be omitted
\numberofauthors{3}
\author{
  \alignauthor 1st Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
  \alignauthor 2nd Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
  \alignauthor 3rd Author Name\\
    \affaddr{Affiliation}\\
    \affaddr{Address}\\
    \email{e-mail address}\\
}

% Teaser figure can go here
%\teaser{
%  \centering
%  \includegraphics{Figure1}
%  \caption{Teaser Image}
%  \label{fig:teaser}
%}

\maketitle

\begin{abstract}
(SZ: will deal with this later) As touchscreen keyboards are software based, the underlying spatial model for key press
classification can dynamically adapt to a number of factors such as the input 
hand posture, the individual, and the target key's position. These adaptations can
potentially improve the overall text entry experience on mobile devices. To 
combine these factors together, we introduce a hierarchical adaptive spatial 
model with back-offs. The hierarchical model consists sub-modules with different levels of
complexity. The highest order module is the most complex and specific one which adapts to 
all three factors whereas the lowest order one is the most general which is independent
of all the factors. As more data is needed to build a more complex module, we introduce
the back-off mechanism such that we can fall back to a less complex module if necessary.
We also evaluate the effectiveness of different adaptive models which gives 
guidance on the priority of these models to use. Finally, we
develop an online input posture classification method for touchscreen keyboard which can be
used with the adaptive spatial model to improve the key probability estimation accuracy.
 
\end{abstract}

\keywords{
  Touchscreen text input; posture adaptation; personalization; adaptive model.
}

\category{H.5.2.}{Information interfaces and presentation}{User interfaces}[input devices and strategies]

\terms{
  Human Factors; Measurement.}

\section{Introduction}
%(sz: I am rewriting the intro. Given the complexity of the paper, the intro
% will focus on giving an storyline of the entire paper, so people can read/understand the rest of the paper to a varying degree, but still get the main message).

The advent and rapid growth of touchscreen based smartphones and tablets have 
made finger typing on touchscreens an everyday information input activity. 
Touchscreen keyboards, which can also be called Smart Touch Keyboards (STK) have 
advanced in technology in the past few years. Taking the publicly available open
source Android keyboard as an example, a modern touch screen keyboard uses 
language modelling, spatial and edit distance based correction and other 
sophisticated techniques to predict, correct, and complete the user’s imprecise 
typing. Despite these engineering achievements, text input continues to be a 
mobile user experience bottleneck, particularly for business and productive
use~\cite{Bao:2011}. Any further improvement to keyboarding experience, even by
a small amount, is desired and important considering hundreds of millions people use their smartphone or tablet everyday.

One compelling direction of research for further improvement of touchscreen 
keyboard experience is adaptation and personalization of keyboard spatial
models.  A spatial model converts a touch point into probabilities of different 
letters. Its adaptation and personalization are most compelling on large touch 
surfaces where one can use 10 fingers to do traditional desktop style touch 
(blind) typing. Findlater and Wobbrock~\cite{Findlater:2012} found 
measurable performance improvement when the keyboard touch typing model is 
personalized. This is quite plausible because users have different hand and 
finger sizes and shapes. Typing on a physical keyboard that is designed for the 
“average” user meant the not so average users have to stretch and move their 
fingers to reach all the keys. With soft keyboards, the underlying “keys” can 
shift and adapt to the individual user. Interestingly, they also found while
adapting the underlying model was beneficial, changing the visual layout (visible boundaries) of the keyboard was not to ten finger touch 
typing experience on large screens~\cite{Findlater:2012}.

In comparison to ten finger blind typing on a large touch surface, the
individual  differences in one finger or two thumb typing on smartphones are 
more subtle but still compelling. People have different finger and thumb width 
therefore conceivably different touch precisions (as measured by variance of 
touch points). People may also have different finger and thumb width and shape 
that affect their touch bias (as measured by the mean offset)~\cite{Holz:2011}.
Azednkot and Zhai~\cite{Azenkot:2012} did a systematic study of smartphone keyboard touch
patterns under various typing conditions. We note the following observations and conclusions based on their study:

\begin{enumerate}
  \item People use different ``hand postures'' -- one finger, one thumb, and two
   thumbs -- to type on smartphones. Depending on the situation (e.g. sitting 
   vs. standing or walking), the same individual may also change from one hand 
   posture to another. We cannot assume the same individual will use the same 
   hand posture all the time. Adaptation methods based on lab experiments with 
   one hand consistent posture, such as those in~\cite{Findlater:2012}, while
   giving important insights and promise, may face challenges in real world applications.

   \item These hand postures change the touch patterns. For example for right
   handed users one finger and one thumb typing on the left side of the keyboard
   tend to shift to the right, whereas two thumb typing on the left side tend to shift to the left.

   \item Touch patterns can also be dependent on letter keys. For example for
  one finger typing users touch points tend to shift downward (downward mean 
  offset bias) on the bottom letter row of the keyboard, but not the top row.

   \item Users’ touch points tend to spread wider on a collective bases (polling
   or accommodating all users data together) than on an individual basis.
\end{enumerate}

Together these observations and findings make a strong case and call for 
personalization of smartphone touch keyboard algorithms. However they also 
illustrate the challenge and complexity of personalization. Future advanced 
keyboards may need to adapt to individual differences as one factor,  but it is 
insufficient or even invalid if the keyboard algorithms do not also adapt to
other adaptive factors, such as hand postures and keys (or regions), at the same time. In other words, strong and effective adaptation may need to  take a combinatorial approach to be key, posture, and user specific.

A combinatorial approach raises challenging implementation issues. First, there 
need to be a large number, such as 26 keys $\times$ 3 postures = 78, of
(sub)models for each individual user. Collecting sufficient amount of data to 
build each submodel may take too long a time to be practically useful. Some 
letters, such as Z and X occur infrequently in text input so it would take a 
long time to gather enough data to build spatial models specific to these keys. 
Second, if an STK does have a large number of (sub)models, model selection can
be  a significant challenge.  Since each (sub)model is specific to a
combination  of factors, a wrong selection may actually hurt the input decoding
quality.
Correct model selection requires an accurate identification of the current mode 
-- a combination of adaptive factors . While it is relatively easy to identify 
the individual (by for example device login) and letter key, it is not so easy 
to identify what hand posture the user is applying to each tap. Conceivably we 
can use for example high resolution optical sensors to help differentiate hand 
postures, but they may not be available in the near term for consumer
lightweight mobile devices.

To address these challenges, we propose and explore a hierarchical back-off 
approach to building adaptive STK spatial models. Adaptive keyboards developed 
in such an approach, when put in use by an individual user, first start with a 
base, generic, and standard spatial model which is user, key, and posture
invariant.  A hierarchy of submodels, ranging from the generic (down to the base model) to the specific (e.g. a spatial model for the letter W when tapped with the right index finger by the current user), starts as dormant models. Each touch input point is used not only for input decoding but also for building one or more submodels which the touch point belongs. When a submodel “matures” in that a sufficient amount of data is available to train it, it becomes active. A mature model will continue to renew itself with new use data to accommodate  slow and long term change of user behavior. When multiple submodels are active, the system first identifies the current input mode and then applies a more specialized model if its corresponding model has matured and if such a mode is classified with high confidence. If either of the conditions is not met, the system backs-off to a more general model or the base model. This hierarchical back-off may offer the following advantages to smart touch keyboard adaptation:
(sz comments: perhaps some sort of schematic illustration is needed here, about updates, use, classification etc).

\begin{enumerate}
\item It (potentially) does specific and fine grained adaptation, not only to
the individual user as a lumped-together entity, but also hand posture and keys. It is therefore more practical and less brittle since it does not assume one user would always use the same hand posture in all situations.

\item It is conservative. Adaptation is only applied if and only if the more
 specialized mode is confidently detected and when its corresponding submodel is mature. It is biased towards the standard base model. In the worst case it is not different from or worse than the standard model. It therefore minimizes the risk of over adaptation and transitional instability when the user changes typing mode.
 
\item The system does not require a separate training (data collection) phase
for each individual. It is more practical to launch such a adaptive system.

\item The system continually updates and renewal itself, so it can accommodate
long term user behavior change.
\end{enumerate}

Such an approach also raises many questions, challenges, and problems which will be addressed in the rest of the paper. Here we give a brief guide and outline these problems and their solutions.

First, “the devil is in the detail”. What we propose is a rather complex
approach  involving multiple phases and components. An actual modern smartphone 
keyboard involves even more components such as a language model, a decoder, an
event handling system and the visual user interfaces.  Can a system really work 
when all of these are put together? Would any other components and functions of 
an entire system (e.g. a language model) washes off or even counteract with 
adaptation? Is it technically feasible as a real time interactive system? To 
address these questions we have built working keyboard prototype by implementing
the proposed hierarchical space models that does updates and back-off in a
research keyboard called Delight Keyboard (given a screenshot figure?) on 
Android OS. The greater details of the Delight keyboard is beyond the scope of 
this paper, but the following is pertinent to the feasibility demonstration of 
this paper:  Delight is a working system with a built-in language model and all 
essential functions of a modern commercial level smartphone keyboard.

Second, while the observations made in~\cite{Azenkot:2012} is quite unambiguous about 
key, hand posture, and individual being reasonable and adaptive factors, their 
relative contribution needs further investigation.  We will report one analysis
on the relative corrective power of various spatial models specific to the
combinatorial factors of key, hand posture,  and individual in section 
``Comparison of Spatial Models''.

Third, in section ``Input Hand Posture Classification'' we will present a 
detailed SVM-based classifier of hand postures that returns mode identification 
of two-thumb vs. single-finger (including one-thumb) hand postures from user’s
natural touch points while entering text.

Fourth, assume perfect classification, does higher order specific models really
 offer better error corrections than a lower order or base model? We will
 address  this question in the “Off device simulation” section (SZ, I don’t like the title) which found in our dataset individual specific spatial models can reduce error rate by is about 12\%; and letter key specific spatial models can reduce error rate by about 15\%. The combination of the two can potentially give further improvement. (I copy and edited these from the old intro, not sure if I got it right and put it in the right place).


Finally, does an implemented system work in real time against real user input? Section “online simulation ,..” (I don’t like the title) tests that. 

(from here on is the old intro, some of its text can be reused and merged with the current intro or the rest of the paper. TBD)
Mobile devices, such as smart phones and tablets, with touchscreens often use
a graphically rendered image as a keyboard. Such touchscreen keyboard is also called
soft keyboard. The lack of tactile feedback and the small key size makes typing on
such a keyboard slow and error prone \cite{Brewster:2007, Rabin:2004}.
As a result, modern touchscreen keyboards are error-tolerant. They can correct sloppy touch
events to user intended words based on a combination of language model prediction 
and spatial model estimation \cite{AlFaraj:2009, Aulagner:2010, Goodman:2002, Gunawardana:2010}. 


(This paragraph and example is quite subtle and difficult to follow, perhaps we need to move this paragraph to a later section). Our goal is to improve the probability estimation of the intended key for each touch point.
At the spatial level, this is mostly important for touch points that lie near the 
boundary of the keys. For example, Figure~\ref{fig:e-w-ellipses-1} shows several touch points (red dots)
near the boundary of ``E'' and ``W''. These touch points are from users using two-thumb input.
The intended key is ``E''. With a simple spatial
model where each key has the same model, say a Gaussian model \cite{Goodman:2002} of 0 mean offsets, the points
at the left side of the boundary would have a higher probability of targeting ``W''.
With a model that adapts to postures and keys, however, those points will still have higher
probability of targeting ``E''. This is because the Gaussian models (presented
by the blue 0.95 confidence ellipses in Figure~\ref{fig:e-w-ellipses-1}) for the ``W'' and
``E'' keys have left horizontal shifts from their corresponding centers for the two-thumb input posture. 

\begin{figure}[tb]
 \includegraphics[width=0.9\columnwidth]{figures/ellipses-two-thumb.pdf}
  \caption{Gaussian distributions of the touch points from two-thumb input. The
  blue ellipses represent the 0.95 confidence intervals of the Gaussian
  distributions.}
  \label{fig:e-w-ellipses-1}
\end{figure}

Our cross-validation analysis, off-device simulation and on-device simulation based
on data collected from 32 users show
that both posture and individual adaptation can improve the key probability estimation. 

In the real world application, posture and individual adaptation need to be
online and in real-time, and these can introduce errors. For instance, when the user switches posture,
the adapted spatial model may in fact give less accurate estimate if the posture classification
is wrong. For individual adaptation, we need enough data points to build
an accurate model because the points we use to update a model may not be accurate. 
To mitigate these problem and consider all the different factors of adaptation, we 
introduce a hierarchical spatial model with many sub-models.  
This means that if the confidence of the posture classification is not high or the sub-model for a particular user, posture and key combination is 
not valid, we back-off to a more general model that only adapts to two, one or even none of 
the factor. 

The paper makes the following contributions. First
we propose a hierarchical adaptive spatial model that combines different
ways of spatial adaptation to improve the accuracy of key probability estimation, and provides seamless back-offs when necessary.
Second we compare the effectiveness of different adaptive strategies.
The result provides a guidance on the priority of the adaptation strategies to use during 
back-off. Third we develop a posture classification method that gives 86\% accuracy in
classifying each touch point into either one-finger or two-thumb input. Finally, we 
combined posture classification and the hierarchical adaptive spatial model in off-device and 
on-device simulation and show that posture and individual adaptation can improve the key probability estimation.

\section{Research Methods}

As smartphone keyboard become more advanced and more sophisticated, and given the kind relatively complex solutions proposed that involve multiple components, multiple phases, and learning,  we fear the traditional lab experiments based HCI evaluation method may not be efficient or sensitive enough for researchers to make rapid progress. In this paper we use a combination of HCI and ML (machine learning) evaluation methods, along with algorithm and system development. 

We first select a smartphone typing dataset, Pepper, as the empirical basis of training and (cross) validation. The experiment that generated the Pepper dataset had been peer reviewed and published  \cite{Azenkot:2012}. Briefly, the Pepper experiment involved 32 participants who were given random phrases to type on a “data collector” or a “wizard of oz” keyboard run on a Android touchscreen phone.  The participants were encouraged to type as naturally as possible and not to correct any errors. The goal was to collect user’s touch patterns by their natural instinct with as little concerns to technology constraint as possible. The Pepper experiment was between-subject in which each participant used one hand posture to type.
For consistency, we removed the data from 2 left-handed users in our analysis, and are left with data from 9 users using one-index-finger input, 11 users using one-thumb input and
10 users using two-thumb input.  Since we found much less difference between the index finger condition and the single thumb condition and due to mode classification reliability concerns, we combine the index-finger input and one-thumb input together as one finger condition. We also filtered out touch points that are 1.5 times the height of the key away from the center of the target key, as did in  \cite{Azenkot:2012}. The ratio of the number of users using one-finger input to that using two-thumb input is kept the same for the training and testing data sets throughout the cross-validation. (not clear exactly how that works -- there were more in the one finger condition). 

A basic dependent variable (measure) of the dataset and any models built from it is “character error rate”. This is measured by the string difference between the character in the target phrase and characters determined from the touch points via a spatial model (SZ: did we use edit-distance? in that case we should cite http://dl.acm.org/citation.cfm?id=1188819). Note although this rate can be viewed as a percentage of the total number of characters in the target phrase, it is to be interpreted with precaution. First, 0% error rate may never be achievable given how the dataset was achieved. Second the percentage … (I will write more about this later)




\section{Related Work}

There is a body of active research on using spatial model, language model, or a combination
of the two to improve text entry accuracy on a soft touchscreen keyboard. For examples, 
Al Faraj et al. \cite{AlFaraj:2009} and Magnien et al. \cite{Magnien:2004} both use
visual highlight of the next possible keys to aid users' typing. Their predictions of the next keys are based on a language model. As our focus is on the 
spatial model, we will also mainly look at the related work in this aspect.    

Kristensson et al. \cite{Kristensson:2005} propose a geometric pattern matching technique to improve 
stylus input accuracy. They match the geometric pattern of the touch points on a stylus keyboard against patterns formed by 
the letter key center positions of legitimate words in a lexicon. Similar to this approach,
they also develop a gesture-based stylus input method where users only need to stroke between the keys \cite{Kristensson:2004}.
Their approaches essentially use a combination of spatial and language models. However, 
their spatial model is not adaptive as they treat the underlying spatial model for each key as having 0 offsets from the corresponding visual key center. While our focus is on tapping input, the same adaptive spatial model approach
can be potentially applied to the gesture-based input.

In terms of spatial model that is adaptive to the keys (i.e. each key has its own model instead of
sharing the same one), Goodman et al. \cite{Goodman:2002} use bivariate Gaussian distribution with means, and
covariance matrices computed separately for each key in their study on stylus input. Zhai et al. \cite{Zhai:2002} also show that
the hit points for each key on a Metropolis keyboard \cite{Zhai:2000} are normally distributed and 
the centers of the distributions shift in different directions depending on the positions of
the keys. In their relative keyboard input system, Rashid et al. \cite{Rashid:2008} also use a different bivariate
Gaussian for each key. The error rate of their system is high because the lack of 
a priori determined keyboard position.

Building on \cite{Goodman:2002}, Gunawardana et al. \cite{Gunawardana:2010} use restricted bivariate Gaussian
models in their anchored key-target resizing method. Key-target resizing means dynamically
adjusting the underlying target areas of the keys based on their probabilities. The probabilities can 
be a combination of spatial model and language model probabilities.
They argue that overly aggressive
key-target resizing can sometimes prevent users from their desired text, and hence violate
users' expectation about keyboard functionality. They ensure that touch points within
the anchor area of a key is always detected as that key irrespective to the language model.

There is also a number of research related to personal adaptation. 
Rudchenko et al. \cite{Rudchenko:2011}
developed a text entry game called \textit{Text Text Revolution} that provides 
targeting words for users to type to improve their typing experience. As a side effect,
the game also generates labeled touch point data which can be used as
training data to build the spatial models. They explore the effect of personal adaptation
by using the touch points from the first 10 rounds (about 250 characters and 50 words per round) of each 
participant's game play to build the personalized model for each key, and simulating the key detection
process for the second 10 rounds. Their result shows that with key-target resizing based on
spatial model only and using the training data from all the users combined
gives an error reduction of 18.9\% over no key-target resizing. When using personalized
key-target resizing, there is a further 2.84\% error reduction.
Their results show the benefit of individual adaptation in an ideal condition where the 
intended key is known. In the real world application, the keys users intend to hit are unknown and
can only be inferred based on the current spatial and language models. In our simulation, we assume the 
intended keys are unknown when building the user adaptive spatial model for each key dynamically as the user types , and hence the result may be closer to the real world situation. 

Findlater et al. \cite{Findlater:2012} uses a J48 classifier to classify
each key-press to specific keys for ten-finger touchscreen typing. They
focus on individual adaptation and suggest that personalized touch keyboard
 can improve typing speed.  
In their user study, each key was initially seeded from 5 points sampled from
a bivariate Gaussian distribution, and the keyboard only started adapting
after a minimum of 10 points were collected from key presses. They did not
give reasons about the choice of these numbers, and did not explore the
effect of these numbers with respect to accuracy. 

The study from Findlater et al. also shows that displaying the adaptation visually can hinder
the performance. This result is also supported by the findings from Himberg et al. \cite{Himberg:2003} who 
studied visually adaptive nine-key numeric keypads for individuals.  

The key and individual adaptive methods mentioned earlier all assume that users' input posture
remain the same. We observe that the same individual may change hand posture even on the same device. 
The study from Azenkot and Zhai [1] shows that there are significant differences 
in typing speed and error rate between two-thumb input posture and one-finger 
input posture. More importantly, the horizontal and vertical offsets are 
different for each key and posture combinations. The most prominent difference is that for
one-finger input, the touch points for the keys on the left side of the keyboard tend to
shift to the right from the center of the target key whereas for two-thumb, the shift for those
keys is to the left. This suggests that automatic posture detection and posture
adaptive spatial model can potentially improve key detection accuracy. They listed those observations but
did not further investigate how posture adaptation can be implemented and how it can actually affect key probability estimation accuracy.

The idea of back-off to a lower order model when a higher order more specific model is not available is commonly used in language modelling for speech recognition. (a few more words about N-gram modelling plus a citation to a survey here).


Finally, various researchers have explored other dimensions to improve the overall
text input experience on touchscreen keyboard. One dimension is using hardware
augmentations to provide vibro-tactile feedback \cite{Brewster:2007, Hoggan:2008}. 
Another dimension is using alternative keyboard layouts that are optimized for typing speed (wpm)
based on Fitts' law and character level digraph frequencies \cite{Zhai:2000, MacKenzie:1999}.
These dimensions are orthogonal to the language and the spatial models, and can be potentially 
combined together to further increase the input accuracy and speed.

\section{Hierarchical Adaptive Spatial Models}
Previous research has shown that users' finger touch points to the keys on a touchscreen
keyboard can be modeled as bivariate Gaussian distributions $N(\underline\mu, \Sigma)$
where $\underline\mu \in \mathbb{R}^2$ is the mean $(x, y)$ offsets from the center of
each key's bounding box, and $\Sigma$ is a $2\times 2$ covariance matrix  
\cite{Azenkot:2012, Goodman:2002, Rashid:2008}.
In this way, the spatial model can be viewed as a generative Gaussian mixture
model.  Given a pair of touch point coordinates $\underline x \in \mathbb{R}^2$, 
we can estimate the key probabilities by computing
$p(\underline x | k)$ for each $k$ from a set of possible keys based on the
spatial model with the parameter vector $\underline\theta$.
We adopt this general model in our analysis of the adaptive spatial models.
Different adaptation methods mean different ways of parameterizing the model, i.e., different
$\underline\theta$.

A hierarchical
spatial model as we proposed in the introduction consists of a number of sub-models.
The entire model can be viewed as a hierarchy of sub-models in different
“orders” (Figure. \ref{fig:hierarchy}).

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/hierarchy.pdf}
  \caption{Hierarchical adaptive spatial model}
  \label{fig:hierarchy}
\end{figure}

The zeroth order is the base model which is key, individual, and posture
independent. This is the most general model combining all data together. The
higher order models consist of a combination of spatial models that adapt to each
key position, the hand 
posture (e.g. one-finger or two-thumb), and the individual user. 

The higher the order of the sub-model, the more data is required to build the model because
the model is more complex with more parameters. This means that each combination of the 
factors needs sufficient number of samples to build a reliable model. Each 
sub-model would only become active when its reliability passes a set 
threshold (e.g. more than 100 points had been collected). Otherwise these models
are still ``growing'' but in ``dormant'' mode, and in these cases, a lower order model (back-off) will
be used instead.

In the key probability estimation process, a higher order more specialized model
is used if it meets a set of conditions such as a particular posture mode is detected with high 
confidence and the corresponding model (e.g. key ``E'' for user 1 using
one-finger) is available (live, matured).
Otherwise we back off to a lower order model, all the way to a base model which 
is key, individual and posture independent if necessary. 

Figure~\ref{fig:hierarchy} shows a complete hierarchy of the sub-models with all
possible combinations of the three adaptive factors. However, depending on the
relative effectiveness of the sub-models, it is not necessary to include all of
them in the implementation. In this paper, we focus on analyzing the key
adaptive model, posture and key adaptive model and user and key adaptive model.
The order of the
back-off process, and the priority of the models at the same level to use can
also be design choices, but the analysis in the next section gives
guidance and suggestion on how to determine the order.

\section{Comparison of Spatial Models}
We compare key detection error rate with different models to analyze their
relative effectiveness (Table \ref{tab:comparison}). This can inform us the order of the
back-off models to use when there is not enough data for higher order models.
10-fold cross validation is used, and the training and testing data sets have
different users.

\begin{table} [tb]
  \centering
  \begin{tabular}{|l|c|}
    \hline
    \tabhead{Spatial model} &
    \multicolumn{1}{|p{0.2\columnwidth}|}{\centering\tabhead{Key detection
    error rate}} \\
    \hline
    Distance from the center of the keys & 7.976\% \\
    \hline
    \multicolumn{1}{|p{0.7\columnwidth}|}{Base model (same Gaussian model for
    all the keys with a full covariance matrix)} & 7.853\% \\
    \hline
    Key adaptive model  & 8.023\% \\
    \hline
    Posture and key adaptive model & 7.058\% \\
    \hline
    Individual and key adaptive model  & 6.845\% \\
    \hline
  \end{tabular}
  \caption{Comparison of key detection accuracy (no language model) with
  different spatial models using 10-fold cross validation.}
  \label{tab:comparison}
\end{table}


The simplest base model can have a Gaussian distribution with 0 mean $x$ and $y$
 offsets and the same spherical covariance matrix for all the keys. Key
detection based on this model is essentially choosing the key that has the shortest Euclidean distance from the tapping coordinates. 
One step beyond this is having a full covariance matrix $\Sigma$ trained from the
training data, but still using the same Gaussian model $N(\underline 0, \Sigma)$ for each key.

\subsection{Key Adaptation}
A basic key adaptive model is a bivariate Gaussian model
$N(\underline\mu_k, \Sigma_k)$ for each key $k$ built  using data from many different
users.
Then the key detection process involves choosing the key $\hat k$ whose Gaussian
model gives the highest probability for the given tapping coordinates
$\underline x$, i.e.,

\begin{align}
\hat k = \arg\max_k p(\underline x|k)
\end{align}

The difference in key detection accuracy between using the base model only and
the key adaptive model is not big. It is even surprising that key adaptive model
gives slightly lower accuracy (contrary to the result shown in
\cite{Rudchenko:2011}). A closer look at the data shows that the most frequent
error is confusing ``E'' with ``W''. Figure \ref{fig:key-adaptive} shows the effective areas of the keys
when using the key adaptive model. Each colored area presents the region such that if the
user tap in that region, the underlying spatial model will classify that key with the 
corresponding key label. We can observe that the area of ``W'' key goes slightly beyond 
the boundary between ``E'' and ``W''. This is because there are more one-finger input users in the data set, 
and there tend to be a right horizontal offset for keys on the left side of the keyboard
when using one-finger input. However, for
the two-thumb input, there is usually a left horizontal offset. Hence when we use
this spatial model , there are more errors for the two-thumb input data.

\begin{figure}[tb]
  \centering
  \subfigure[Key adaptive model]{
    \includegraphics[width=0.47\columnwidth]{figures/key-model.pdf}
    \label{fig:key-adaptive}
  } ~
  \subfigure[Posture and key adaptive model for one-finger input]{
    \includegraphics[width=0.47\columnwidth]{figures/posture-t.pdf}
    \label{fig:one-finger}
  }
  \subfigure[Posture and key adaptive model for two-thumb input]{
    \includegraphics[width=0.47\columnwidth]{figures/posture-tt.pdf}
    \label{fig:two-thumb}
  }
  \caption{Comparison of effective key areas with different spatial models}
  \label{fig:key-boundary}
\end{figure}

This suggests that key adaptive model may not always be effective unless we
have enough data and a balanced number of postures in the training data. 

The key spatial model can also be more specialized to include bi-letters
(also referred to as ``digraphs'' in \cite{Zhai:2000}) patterns that occur
frequently, for instances, ``H'' followed by ``E'', ``T'' followed by ``H'' etc.
Figure~\ref{fig:biletter} shows the 0.95 confidence ellipses of the Gaussian
distributions of the touch points of key ``E'' for different adaptive models. The plot shows that when we combine data
for all the posture together, the distribution of points for ``E'' after ``H'' is
very slightly different from that of all ``E''. But if we look at ``E'' after
``H'' for one-finger input (cyan color), the difference is bigger. Another point 
to note is that, since these are highly frequent patterns, even a small 
improvement in detecting these keys based on these more specialized models may 
give a bigger improvement in the overall key probability estimation accuracy.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/biletter-he.pdf}
  \caption{Comparison of Gaussian models (0.95 confidence ellipses) for letter
    ``E''.}
  \label{fig:biletter}
\end{figure}

Due to the scope of this paper, we do not analyze further about the
effectiveness of adapting to bi-letter patterns, leaving it as a future
work.

\subsection{Posture Adaptation}
Key adaptation becomes more effective when combined with posture adaptation as
shown in Table~\ref{tab:comparison}. There is 12.03\% reduction in error rate 
compared to key adaptation only. The two-sample one-sided paired t-test shows
that the improvement in accuracy is significant when we use posture and key 
adaptation versus key adaptation only (t(29) = -2.4421, p = 0.01).

There can be different levels of complexity for posture adaptation. For the most complex one, we can have
two models for each key for each input postures, i.e., $N(\underline \mu_{y,k}, \Sigma_{y,k})$ for $y \in
\{\text{one-finger, two-thumb}\}$; or we can do posture adaptation only for a certain
number of keys. The best result is obtained when we only do posture adaptation for the keys on 
the left side, and for the keys on the right side, their Gaussian models are
independent of the posture, i.e., $N(\underline\mu_k, \Sigma_k)$.
The error rate for posture and key adaption shown in the table is based on 
posture adaptation for the keys on the left side. 

The choice of this set of keys is not arbitrary. As observed by Azenkot et al. \cite{Azenkot:2012}, the difference in horizontal
offsets of the touch points from different postures are most prominent for the keys on the
left set (Note that for left-handed users, the reverse is probably true). 
In addition, the analysis of variance based on the tapping coordinates from the
data set shows that, for different postures, there are significant differences in the means of
the $x$ coordinate for the keys on the left side of the keyboard ($p < 0.05$). 

Figure~\ref{fig:one-finger} and \ref{fig:two-thumb} show the comparison of effective areas of the keys
with spatial models adapted to one-finger input and two-thumb input respectively. Note how the key areas for the left-side keys shift to the left
for two-thumb input, and shift to the right for one-finger input. The difference in 
the effective key areas is the same concept as key-target resizing mentioned in \cite{Gunawardana:2010, Rudchenko:2011}.

The error rate in Table~\ref{tab:comparison} is based on perfect knowledge of
the posture which represents a lower bound for posture adaptation for this data
set. In the real world implementation, the online posture classification may
introduce errors. To mitigate the problem, the posture adaptive model can be turned on
when we have high enough confidence about the posture classification. The details are explained in a later section.

\subsection{Individual Adaptation}
The individual and key adaptive model gives the lowest error rate compared to the
other models. The error reduction over key adaptive model is 14.68\%.
This suggests that individual and key adaptation can have higher priority in the hierarchical
adaptive model. 

The result in the last row of Table~\ref{tab:comparison} is based on the 
following method. For each fold of the cross-validation, data from the training set are used to 
train the combined back-off key models. For each user in the test set,
50\% of the data for each key is used to train the individual and key adaptive
model, i.e., $N(\underline \mu_{u, k}, \Sigma_{u, k})$ where $u$ is from the test user set.
The accuracy of these data points are tested on the combined key models.
The remaining 50\% of the data for each user are tested on the user adaptive 
models. 

Figure~\ref{fig:user-adapt} shows how key detection error rate for key ``E'' 
changes as the number of points used to build
the personalized model for key ``E'' increases. The error rates are obtained using cross-validation
as well and are based on the touch points that are not used in building the
model. We choose ``E'' as an
example because it has the most number of data points (around 90) for each
user in our data set besides the ``Space'' key. For other keys, there are
relatively small number of data points, and hence it is hard to do the
analysis on them. However, we believe the result would be applicable to other
keys. Also due to the limited number
of data points, we only show the trend until the number of touch points used to build the individual
model is 70. Nevertheless, the figure still shows a general trend, and suggests 
that the minimum number of data points for building a individual key adaptive model
should be at least 60, but a number in the order of a hundred is probably better. When
there are not enough data points, a back-off model like the posture and key adaptive model can be used.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/individual-adapt.pdf}
  \caption{Graph showing how key detection error rate for key ``E'' changes as the number of
  points used to build the individual adaptive model for key ``E'' increases.}
  \label{fig:user-adapt}
\end{figure}

\section{Input Hand Posture Classification}\label{sec:posture-classification}
ABC needs real time classification of the user’s hand postures. A variety of sensors, signals and algorithms can be used in the future to achieve such a function. We developed an online binary hand-posture classifier 
that constantly returns an estimate of the user's current posture (two-thumb or one-finger input) from the user’s text input touch points without additional sensors. 

Let $\mathcal{Y} = \{\text{one-finger}, \text{two-thumb}\}$ be the set of posture
class labels. We describe in detail the classification function that maps input from the
touch points to $\mathcal{Y}$.

Our method of hand-posture classification is based on Fitts’ law which states that the time (T) required to move to a target is a function of the distance (D) to the target and the size (W) of the target (Equation 1).
\begin{align}
T = a + b\log_2(1 + \frac{D}{W})
\end{align}                                                  
The insight here is that we expect the one-finger input posture follows this law,  but two-thumbs input may not. For example, when the user types “al”, it takes longer time to type using one finger because the distance the one finger has to travel from A key to L key on Qwerty is large. With two thumbs, typing “al” can be faster because the touch action switches from left thumb to type “A” to the right thumb to type “L”, no long distance travel is required.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/time-distance.png}
  \caption{Tapping points data from input on a Nexus S phone.}
  \label{fig:time-distance}
\end{figure}

Figure. \ref{fig:time-distance} shows the relationship between the time elapsed 
and the log square distance travelled between consecutive key presses. We can
see that for the one-finger input (blue and red points), the time taken
increases with distance whereas for the two-thumb input, there is no obvious
trend. The difference is more significant when the log square distance (natural
log) is greater than 10 px.

Based on this finding, we include the time elapsed and the log square distance
between two consecutive key presses as the features for the posture classifier. 
To account for individual typing speed differences, we also use normalized time 
elapsed between consecutive key presses as the third feature. It is calculated 
by dividing the time elapsed by the average time elapsed for the last 10 key
presses.

We train a SVM classifier with these 3 features for consecutive tap points that 
are on different sides of the keyboard and whose log square distance is at least
10px. We use 70\% of the data for training and 30\% of the
data for testing. The users in the training and testing data sets are different.

The Pepper (84292 filtered data points) data sets we use consist tapping points 
from different users with different postures. The classification accuracy from
the single tap classifier for keys with previous key on the different sides of
the keyboard 83.559\% (11090/13272).

The single tap classifier gives a probability score $p_y^{\text{single}}$ for each posture for touch
points whose previous key tap is on the different side of the keyboard. Note that
$\displaystyle\sum_{y \in \mathcal{Y}}p_y^{\text{single}} = 1$.
 
In order to classify every key tap and assuming the user does not change posture 
rapidly, we look at a sliding time window of 10 key taps (about 2 words). For 
each time window, we use another SVM classifier with the following features:
\begin{enumerate}
\item Correlation between time elapsed and log distance (this feature has the
advantage of being speed independent) (see Figure. \ref{fig:boxplot}).
\item The average probability score for each tap to be one-finger input.
\item The average probability score for each tap to be two-thumb input.
\item The average number of taps classified as one-finger input.
\item The average number of taps classified as two-thumb input.
\end{enumerate}
The history of the touch points are cleared for every new typing session.
The choice of the size of the sliding window represents a trade-off between the 
accuracy of the classification and how responsive the system is when the user
changes posture. We found that the assumption that the user does not change posture
often within 2 words is reasonable, but more work can be done to investigate this
aspect, and even to test with a window size of 1 (i.e. not 
looking at the history).

The sliding time window classifier gives a final probability score $p_y$ for posture
$y$ for each touch point. Again $\displaystyle\sum_{y\in \mathcal{Y}}p_y = 1$. To evaluate the classification accuracy, we set the the
classified posture to be $y$ if $p_y > 0.5$. With this, the overall classification 
accuracy for each touch point with a sliding time window
is 86.401\% (23128 out of 26769 touch points).

Because of the sliding window approach, the posture for the first few touch points  
for each new session is unknown. In this case, the system backed off to a lower order spatial 
model (key adaptive or base model). Furthermore  it turns on the posture 
adaptive spatial model only when the probability score for one posture is much 
higher than the other.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.8\columnwidth]{figures/boxplot.pdf}
  \caption{Correlation between time elapsed and log square distance between
  consecutive key presses for every 10 keys. There is a stronger correlation for
  one- finger input than that for two-thumb input.}
  \label{fig:boxplot}
\end{figure}

\section{Implementation and Simulation}
The key probability estimation process with the proposed hierarchical adaptive model fits nicely with the
Chain of Responsibility design pattern.
Figure~\ref{fig:chain-of-responsibility} shows a simplified version of an object
diagram showing the interaction between various models. Each higher model can
have a reference or references to lower order models. When given a pair of touch
point coordinates, the system queries the highest order model for a Gaussian
model for a particular individual/posture/key combination. If it is not present, 
the higher model calls the lower model, and the
query propagates until a Gaussian model is found. 

\begin{figure}[tb]
  \centering
  \includegraphics[width=1\columnwidth]{figures/chain-of-responsibility.pdf}
  \caption{An object diagram showing the interaction between higher and lower
  order spatial models.}
  \label{fig:chain-of-responsibility}
\end{figure}

We implemented a prototype similar to what is described above with the 
online posture classification. We did a simulation using 20 users' data for training
both the posture classifier and spatial model, and tested on the other 10 users' 
data. The percentages of one finger input and two thumbs input postures are the same in both the training and testing data sets.

\subsection{Off-device Simulation}
We did off-device simulation to compare
key detection error rate using different spatial models without language model.
Table~\ref{tab:off-device} shows the results.

\begin{table}[tb]
  \centering
  \begin{tabularx}{\columnwidth}{|X|c|}
  \hline
  \tabhead{Spatial model} & \tabhead{Error rate} \\
  \hline
  \multicolumn{1}{|p{0.7\columnwidth}|}{Base model (same Gaussian model for
    all the keys with a full covariance matrix)} & 8.641\% \\
  \hline
  Key adaptive model & 8.708\% \\
  \hline
  Posture and key adaptive model & 8.394\% \\
  \hline
  Individual and key adaptive model  & 7.621\%
  \\
  \hline
  Posture, individual and key adaptive model &  7.498\%
  \\
  \hline
  \end{tabularx}
  \caption{Off device simulation result}
  \label{tab:off-device}
\end{table}

\subsubsection{Posture Adaptation}\label{sec:off-device-posture}
The posture and key adaptive model shown here uses the posture classification
method described in the previous section. As a result, the
key detection error rate for using this model is compounded with the posture
classification error rate as well. 

An error in posture classification will lead to the choice of wrong spatial model,
and hence adversely affect the key detection accuracy. To mitigate this problem, we
adopt a conservative approach, and only use posture adaptation when the confidence of
the classification result is high.

The confidence of the classification is reflected by the pair of probability 
scores $(p_{\text{one-finger}}, p_{\text{two-thumb}})$ returned by the classifier. 
We can set a threshold $T_{\text{posture}}$ such that the input posture is classified
as $y$ only if $P_y \ge T_{\text{posture}}$ . Otherwise the posture is treated as
unknown and we back-off to a lower order spatial model.

There is also a trade-off in setting the threshold $T_{\text{posture}}$. The higher
 $T_{\text{posture}}$ is, the fewer the number of errors there are in posture classification, but at the same time,
 posture adaptation will be used for fewer number of touch points. In other words, 
 more touch points will be classified as from unknown posture and no posture adaptation 
 is used for these touch points. Figure~\ref{fig:posture-confidence} shows how
 the key detection error rate changes as the confidence threshold increases. It 
 shows that there is an optimal level of the threshold beyond which the error rate
 increases because we no longer take the advantage of posture adaptation.

\begin{figure}[tb]
 \includegraphics[width=0.9\columnwidth]{figures/error-confidence.pdf}
  \caption{Graph showing how key detection error rate changes with confidence
  threshold for posture classification.}
  \label{fig:posture-confidence}
\end{figure}

The error rate when using posture and key adaptive model shown in Table~\ref{tab:off-device}
is obtained by setting $T_{\text{posture}} = 0.94$.

To further investigate the effect of posture adaptation, we looked at the detection
errors when using key adaptive model only as compared to when using posture and key adaptive model.
Figure~\ref{fig:confusion-matrices} shows the confusion matrices from the key detection
simulation for the key adaptive model and the posture and key adaptive model. Each 
confusion matrix is a representation of the key detection errors. The row labels are
the target keys, and the column labels are the predicted keys. The color of the cells
represents the number of errors for a particular pair of confusion. The more red the color,
the greater the number of errors. Figure~\ref{fig:error-key} and \ref{fig:error-posture}
shows errors when using key adaptive model and posture and key adaptive model respectively.
The most frequent mistake for both models are ``A'' and ``S'' confusion. Figure~\ref{fig:error-key-posture}
and \ref{fig:error-posture-key} shows errors in one of the models but not in the other one.
We can see that when using posture and key adaptive errors we also incur errors
that are not present when using key adaptive model alone. However the number of these
errors are much smaller compared to the errors corrected.

\begin{figure*}[tb]
  \centering
  \subfigure[Errors when using key adaptive model]{
    \includegraphics[width=0.49\columnwidth]{figures/sim-result-1.pdf}
    \label{fig:error-key}
  } 
  \subfigure[Errors when using posture and key adaptive model]{
    \includegraphics[width=0.49\columnwidth]{figures/sim-result-2.pdf}
    \label{fig:error-posture}
  }
  \subfigure[Errors when using key adaptive model but not when using posture and key
  adaptive model]{
    \includegraphics[width=0.49\columnwidth]{figures/sim-result-1-2.pdf}
    \label{fig:error-key-posture}
  }
  \subfigure[Errors when using posture and key adaptive model but not when using key
  adaptive model]{
    \includegraphics[width=0.49\columnwidth]{figures/sim-result-2-1.pdf}
    \label{fig:error-posture-key}
  }
  \subfigure{
    \includegraphics[width=0.3\columnwidth]{figures/sim-result-colorkey.pdf}
  }
  \caption{Confusion matrices for different
  spatial models from off-device key detection simulation. The row labels are the
  target keys, and the column labels are the predicted keys.}
  \label{fig:confusion-matrices}
\end{figure*}

Figure~\ref{fig:error-key-posture} also shows that the most number of
corrections by using posture and key adaptive model is for the ``E'' and ``W'' pair. Figure~\ref{fig:e-w-ellipses}
shows a closer look at the Gaussian models for the two keys for the different
spatial models. Each ellipse represents the 0.95 confidence ellipse of the Gaussian model built 
based on a set of touch points.
Each black ellipse is based on the touch points intended for either ``W'' or ``E''. 
For the blue ellipses, they are drawn similarly but only touch points from two-thumb input
are included. The red points are the touch points that are detected as ``W'' when the target
key is ``E'' when using the key adaptive model. We can see the black ellipses are shifted
slightly to the right probably because there are more touch points from one-finger input in the training
data. The causes the touch points on either sides of the boundary between ``W'' and 
``E'' to be mis-classified as ``W''. However, the ellipses based on the posture and key
adaptive model for the two-thumb input shifts to the left slightly, and this changes
the classification of those boundary points to ``E'' correctly.

\begin{figure}[tb]
  \centering
  \includegraphics[width=1\columnwidth]{figures/key-posture-ellipse.png}
  \caption{Comparison of Gaussian distributions.}
  \label{fig:e-w-ellipses}
\end{figure}

\subsubsection{Individual Adaptation}
For individual adaptive model, we set the minimum number of points needed to build the
Gaussian model for a particular key for a particular individual to be 50. Ideally we would want like to set this number higher for better model reliability. However the current number is 
limited by the amount of data we have because there are not many keys that has 
the number of touch points be greater than 50i out dataset. Unlike the analysis using cross-validation
where we assume we know the target key perfectly, during online implementation, we can
only make the best possible guess about the user's target key and use the touch point
coordinates to update the Gaussian model for that particular key.

For every touch point, we compute the probability for each key given the underlying spatial model.
Then we use the $(x, y)$ coordinates of the touch point to update the Gaussian model
for the most probable key. Updating the Gaussian model involves computing the running
average of the $x, y$ offsets from the center of the key and the covariance matrices. The counter 
for the number of points used for a particular key Gaussian is maintained so that we
know when a particular Gaussian model becomes valid, i.e. has enough data points.

When there is not enough data points, the system backs-off to a lower order model.
Here we can have a choice of whether backing-off to the posture and key adaptive model or 
to the key adaptive model. Backing-off to the posture and key adaptive model means
classify the user's current posture and use the corresponding posture and key model for key detection instead
of just using the key model which is posture independent. The last two rows in 
Table~\ref{tab:off-device} shows that there is also a slight more error reduction  in backing-off to
the posture and key adaptive model.

Note that because the data set we have is from a between-user study, we cannot look
at the effect of posture adaptation for each individual, i.e., each individual has two Gaussian models
for each posture and key combination.

\subsection{On-device Simulation with Language Model}

(Move implementation paragraph here, along with a possible screenshot? Also give the prototype a name. Call it Delight-SA or something. Again give the reader the sense it is a real working system)

Delight-SA runs on Android devices. Its input decoding process is based on combining a language model with the keyboard spatial model. The language model is a most basic one which gives the same probability for all the possible words in the dictionary. It does not correct substitution, insertion or deletion errors either. This is to establish
a baseline. Future work should further study the interaction between the power and complexity of a language model and the power and complexity of a spatial model.

During the decoding process, given a sequence
of touch points $\underline x_1\ldots\underline x_n$, Delight-SA computes 
the probability of each touch point to
each key in a candidate word using the spatial model.
The probabilities are then combined with the word probability based on the 
language model to give  the final probability of the intended word.

Delight-SA was put to an on-device test. We fed Delight-SA with the Pepper touch data in real time (at the same time intervals the touch data were recorded) through Android’s Monkey event emulation tool. For each user’s data, Delight-SA starts with no user specific spatial models (but with posture specific models?) 

The metric we use is the mean word accuracy score between target phrases and detected
phrases after auto correction. The word accuracy score is based on minimum
word distance (MWD) error rate which is the smallest number of word deletions, insertions, or replacements needed to transform
from the target phrase into the detected phrase divided by the maximum of the 
lengths of the two phrases. Word accuracy score is then equal to $(1 - \text{MWD error rate})\times100$.
The higher the score the better. Again, given how Pepper dataset is collected the absolute MWD score is not necessarily the accuracy percentage a user would experience in practice, but the comparative MWD scores across conditions are informative of the keyboard’s quality.

With key adaptive model only, the final score is 80.078; and with posture and key
adaptive model, the final score is 80.529. Table~\ref{tab:on-device} shows some examples
in the test users where the detected phrases are correct when using posture and key adaptive spatial model, but
are wrong when using key adaptive only spatial model. We can see that in those examples,
the posture and key adaptive model can correctly detect the phrases because it
correctly distinguish the neighboring keys between ``A'' and ``S'', ``S'' and ``D'',
``D'' and ``F'', ``F'' and ``G'', ``W'' and ``E''. 

\begin{table*}[tb]
  \centering
  \begin{tabularx}{0.925\textwidth}{|l|l|l|l|}
  \hline
  \tabhead{Input posture} & \tabhead{Target phrase} & \tabhead{Detected phrase with key adaptive model} 
  & \multicolumn{1}{|p{0.526\columnwidth}|}{\tabhead{Detected phrase with posture and key adaptive model}}\\
  \hline
  two-thumb & the dreamers of dreams & the \textcolor{red}{dream era} of dreams & the dreamers of dreams  \\
  \hline
  two-thumb & handicapped persons & \textcolor{red}{handicap pes} persons & handicapped persons \\
  \hline
  two-thumb & she wears too much makeup & \textcolor{red}{a he} wears too much makeup & she wears too much makeup \\
  \hline
  one-finger & my bare face in the wind & my bare face in the \textcolor{red}{wins} & my bare face in the wind \\ 
  \hline
  two-thumb & a lie makes the nose grow & a lie \textcolor{red}{ma kea} the nose grow & a lie makes the nose grow \\
  \hline 
  two-thumb & the bathroom is clean & the bathroom is \textcolor{red}{cl wan} & the bathroom is clean \\
  \hline 
  two-thumb & travel at light speed & travel at light \textcolor{red}{a peed} & travel at light speed \\ 
  \hline
  two-thumb & traveling requires fuel & \textcolor{red}{travel inf require a} fuel & traveling requires fuel \\
  \hline 
  two-thumb & most golfers love the game & most \textcolor{red}{gold ers} love the game & most golfers love the game \\ 
  \hline
  two-thumb & win first prize & win \textcolor{red}{dir st} prize & win first prize \\ 
  \hline
  two-thumb & if at first you fail & if at \textcolor{red}{dir st} you fail & if at first you fail \\ 
  \hline
  \end{tabularx}
  \caption{Examples of on-device simulation where the detected phrase is correct
  with posture and key adaptive spatial model and incorrect with key adaptive spatial
  model.}
  \label{tab:on-device}
\end{table*}

There are also a smaller number of cases where the detected phrases using key 
adaptive model is correct, but the ones using posture and key adaptive model are
wrong. These usually occur when the posture classification is wrong. 

The result shows that the posture adaptive spatial model can potentially be combined 
with language model to give better auto correction result even though posture
classification may not be perfect. 

\section{Discussion}
The analysis and simulation results in the previous sections suggest that we
can give higher priority to individual adaptation when we do not have enough data for
the highest order model (i.e., the posture, individual and key adaptive model). 
If there are still not enough data for the individual and key adaptive model, we 
can back-off to posture and key adaptive model. Figure~\ref{fig:partial-hierarchy} 
shows a possible partial hierarchical model and back-off paths taking into consideration
of the effectiveness of the adaptive models. The numbers indicate the order of the 
sub-models to use during back-off. The result in the
last row of Table~\ref{tab:off-device} is obtained using this spatial model.

Touchscreen keyboard posture detection is a new topic and we believe there is still
large room to improve the classification accuracy. More features such as sensor data from 
the accelerometer and the gyroscope in the mobile device can be evaluated to see whether
they can help with the classification. Other input postures such as ten-finger input
on tablets can also be explored with the proposed approach in the future. 

More work can be done to investigate the touch points distribution pattern of bi-letters (digraphs) 
for frequently occurring pairs. We believe that because these patterns occurs so frequently, even
a small improvement in the key probability estimation accuracy can improve the overall
user experience in text entry.  

The on-device simulation with posture adaptation and a simple language model shows promising result, but there are
still a lot of work to be done to explore the interaction between posture and individual adaptation and
a more sophisticated language model. It would also be interesting to study how
to use posture detection to guide transposition error correction, because transposition error
is more likely to occur when two hands are used to type.

\begin{figure}
  \centering
  \includegraphics[width=0.9\columnwidth]{figures/partial-hierarchy.pdf}
  \caption{Partial hierarchical model implemented in our prototype.}
  \label{fig:partial-hierarchy}
\end{figure}

An important limitation of our exploration thus far is the limited dataset available. Much greater amount of data than what is typically collectable from lab experiments  is needed in the future to continue this line of work. Methods such as real use logging with strict privacy preservation and game playing (cite text text revolution) can be possibly employed to gather a large body of data. Because of the dataset limit, what we have addressed is fundamentally on an approach to STK spatial model adaptation. The specific (sub)methods, the back-off procedure and sequence, and certainly the parameters learned from the data, may be changed and optimized in the future. 


\section{Conclusion}
We have introduced and evaluated a novel hierarchical adaptive spatial model for
touchscreen keyboard. Through comparative submodel analysis,  offline simulation, and on device test, 
we have shown that both posture and user adaptation for the spatial model can improve
key probability estimation and key detection accuracy. When they are combined, they can
give the most improvement. The adaptations can potentially
improved the auto-correction accuracy when combined with language models. For real world
implementation, the
hierarchical structure gives a systematic way of backing-off  when data is limited
or we want to be conservative, e.g., when the posture classification confidence is not 
high enough. 

We have also developed a new touchscreen input posture classification method
that achieves an accuracy of 86.4\% for classifying one-finger and two-thumb input. When
combined with the adaptive spatial model, the overall key detection accuracy is increased
in our simulation.

\section{Acknowledgments}
We want to thank our team members (names omitted for review) for their insightful
suggestions and help in  our data analysis and implementation of the prototype. 

\balance

% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
\small
\bibliographystyle{acm-sigchi}
\bibliography{chi2013}
\end{document}


